server.port: 8080

#DeepSeek
langchain4j:
  open-ai:
    chat-model:
      base-url: https://dashscope.aliyuncs.com/compatible-mode/v1
      api-key: ${DASH_SCOPE_API_KEY}
      #DeepSeek-V3
      model-name: deepseek-v3
      #DeepSeek-R1 推理模型
      #langchain4j.open-ai.chat-model.model-name=deepseek-reasoner

      log-requests: true
      log-responses: true
  #ollama
  ollama:
    chat-model:
      base-url: http://localhost:11434
      model-name: deepseek-r1:1.5b
      temperature: 0.8
      timeout: PT60S

      log-requests: true
      log-responses: true

  #阿里百炼平台
  community:
    dashscope:
      chat-model:
        api-key: ${DASH_SCOPE_API_KEY}
        model-name: qwen-max


logging:
  level:
    root: debug

